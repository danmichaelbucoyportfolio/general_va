# @title üöÄ Setup: Install ComfyUI & Download Flux2-Klein-GGUF {display-mode:"form"}
# @markdown **Run this once** - Cleans previous installs, sets up ComfyUI with GGUF support

# Clean previous attempts
!rm -rf /content/ComfyUI

# Clone fresh
!git clone https://github.com/comfyanonymous/ComfyUI /content/ComfyUI -q
%cd /content/ComfyUI
!pip install -q -r requirements.txt

# Install custom nodes
%cd /content/ComfyUI/custom_nodes
!git clone https://github.com/city96/ComfyUI_GGUF.git -q
!git clone https://github.com/ltdrdata/ComfyUI-Inpaint-CropAndStitch.git -q

# Install GGUF requirements
!pip install -q folder_paths gguf

!apt-get update -qq && apt-get install -qq aria2 -y -qq

# Create directories
!mkdir -p /content/ComfyUI/models/unet /content/ComfyUI/models/clip /content/ComfyUI/models/vae /content/ComfyUI/input /content/ComfyUI/output

# Download models
print("üì• Downloading Flux2-Klein-9B-GGUF...")
!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \
  "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_K_M.gguf" \
  -d /content/ComfyUI/models/unet -o flux-2-klein-9b-Q4_K_M.gguf

print("üì• Downloading Text Encoder...")
!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \
  "https://huggingface.co/Comfy-Org/flux2-klein-9B/resolve/main/split_files/text_encoders/qwen_3_8b_fp8mixed.safetensors" \
  -d /content/ComfyUI/models/clip -o qwen_3_8b_fp8mixed.safetensors

print("üì• Downloading VAE...")
!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \
  "https://huggingface.co/Comfy-Org/flux2-dev/resolve/main/split_files/vae/flux2-vae.safetensors" \
  -d /content/ComfyUI/models/vae -o flux2-vae.safetensors

import os, gc, sys, torch, numpy as np
from PIL import Image, ImageDraw
import json, base64, random, time
from google.colab import files, output
from IPython.display import display, HTML, clear_output, Image as IPImage

# Setup paths
sys.path.insert(0, '/content/ComfyUI')
os.chdir('/content/ComfyUI')

# Import Comfy core
import nodes
from nodes import NODE_CLASS_MAPPINGS

# Import GGUF (matching Qwen notebook pattern)
from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF

# Import Crop/Stitch
sys.path.insert(0, '/content/ComfyUI/custom_nodes/ComfyUI-Inpaint-CropAndStitch')
from inpaint_cropandstitch import InpaintCrop, InpaintStitch

print("üîÑ Initializing nodes...")

# Core nodes
CLIPLoader = NODE_CLASS_MAPPINGS["CLIPLoader"]()
VAELoader = NODE_CLASS_MAPPINGS["VAELoader"]()
CLIPTextEncode = NODE_CLASS_MAPPINGS["CLIPTextEncode"]()
VAEDecode = NODE_CLASS_MAPPINGS["VAEDecode"]()
VAEEncode = NODE_CLASS_MAPPINGS["VAEEncode"]()
LoadImage = NODE_CLASS_MAPPINGS["LoadImage"]()
SaveImage = NODE_CLASS_MAPPINGS["SaveImage"]()
ImageScale = NODE_CLASS_MAPPINGS["ImageScale"]()
EmptyLatentImage = NODE_CLASS_MAPPINGS["EmptyLatentImage"]()
InpaintModelConditioning = NODE_CLASS_MAPPINGS["InpaintModelConditioning"]()
SamplerCustomAdvanced = NODE_CLASS_MAPPINGS["SamplerCustomAdvanced"]()
RandomNoise = NODE_CLASS_MAPPINGS["RandomNoise"]()
CFGGuider = NODE_CLASS_MAPPINGS["CFGGuider"]()
KSamplerSelect = NODE_CLASS_MAPPINGS["KSamplerSelect"]()

# GetImageSize fix - check if it exists in mappings, otherwise we'll calculate manually
if "GetImageSize" in NODE_CLASS_MAPPINGS:
    GetImageSize = NODE_CLASS_MAPPINGS["GetImageSize"]()
    has_get_image_size = True
else:
    has_get_image_size = False
    print("‚ÑπÔ∏è GetImageSize not in core nodes, using tensor shape method")

# Flux2Scheduler check
if "Flux2Scheduler" in NODE_CLASS_MAPPINGS:
    Flux2Scheduler = NODE_CLASS_MAPPINGS["Flux2Scheduler"]()
    use_flux_scheduler = True
else:
    BasicScheduler = NODE_CLASS_MAPPINGS["BasicScheduler"]()
    use_flux_scheduler = False
    print("‚ö†Ô∏è Flux2Scheduler not found, using BasicScheduler")

# ReferenceLatent check
try:
    from comfy_extras.nodes_model_advanced import ReferenceLatent
    reference_available = True
    print("‚úÖ ReferenceLatent loaded")
except:
    reference_available = False
    print("‚ö†Ô∏è ReferenceLatent not available")

# Custom nodes
unet_loader_gguf = UnetLoaderGGUF()
inpaint_crop = InpaintCrop()
inpaint_stitch = InpaintStitch()

# Helper functions
def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)

def tensor2pil(image):
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))

def get_image_size_fixed(image):
    """Fallback for GetImageSize using tensor shape"""
    if has_get_image_size:
        return GetImageSize.get_size(image)
    else:
        # image is [B, H, W, C]
        return (int(image.shape[2]), int(image.shape[1]), int(image.shape[0]))

# Global vars
output_dir = "/content/ComfyUI/output"
os.makedirs(output_dir, exist_ok=True)
mask_path = None
source_image_path = None
reference_image_path = None

clear_output()
print("‚úÖ Setup Complete!")
